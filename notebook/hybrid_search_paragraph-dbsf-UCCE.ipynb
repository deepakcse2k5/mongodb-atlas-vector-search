{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pymongo\n",
    "import json\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/Users/deemish2/git/mongodb-vector-atlas-search\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_helper import insert_data, update_data, update_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.pipeline import vector_search_pipeline, search_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('nli-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text):\n",
    "    return model.encode(text).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config.yaml', 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "# Load the configuration from the config.yaml file\n",
    "mongo_uri = config['mongodb']['mongo_uri']\n",
    "db_name = config['mongodb']['db_name']\n",
    "collection_name = config['mongodb']['ucce_collection_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to your Atlas cluster\n",
    "mongodb_client = pymongo.MongoClient(mongo_uri)\n",
    "collection = mongodb_client[db_name][collection_name]\n",
    "vector_search_index = \"ucce_vector_index\"\n",
    "search_index = \"ucce_search_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../input/ucce.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_data(data,model,collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update data\n",
    "\n",
    "update_data(model, data, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_terms( data, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in collection.find({'terms':{\"$exists\": True}}).limit(5):\n",
    "\tprint(doc.get('query'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_search(collection, query, index_name, path):\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": index_name,\n",
    "                \"path\": path,\n",
    "                \"queryVector\": generate_embedding(query),\n",
    "                \"numCandidates\": 20,\n",
    "                \"limit\": 10\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 1,\n",
    "                \"sentence\": 1,\n",
    "                \"score\": {\"$meta\": \"vectorSearchScore\"}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    return list(collection.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_results(results):\n",
    "    # Simplified merging logic, possibly just concatenation or more complex merging\n",
    "    combined_results = {}\n",
    "    for result_set in results:\n",
    "        for item in result_set:\n",
    "            item_id = item['_id']\n",
    "            if item_id not in combined_results:\n",
    "                combined_results[item_id] = item\n",
    "            else:\n",
    "                # Example of merging scores, could be more complex\n",
    "                combined_results[item_id]['score'] = max(combined_results[item_id]['score'], item['score'])\n",
    "    return list(combined_results.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "paths = [\"sen_embedding\", \"query_embedding1\", \"query_embedding2\", \"query_embedding3\", \"query_embedding4\"]\n",
    "for path in paths:\n",
    "    results.append(perform_search(collection, query, vector_search_index, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_results = merge_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_scores = {doc['_id']: round(doc['score'],2) for doc in vector_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pipeline(query,index_name):\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$search\": {\n",
    "                \"index\": index_name,\n",
    "                \"text\": {\n",
    "                    \"query\": query,\n",
    "                    \"path\": {\n",
    "                        \"wildcard\": \"*\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 1,\n",
    "                \"paragraph.sentence\": 1,\n",
    "                \"score\": 1,\n",
    "                \"normalizedScore\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "  \"$addFields\": {\n",
    "    \"score\": {\n",
    "      \"$meta\": \"searchScore\"\n",
    "    }\n",
    "  }\n",
    "},\n",
    "{\n",
    "  \"$setWindowFields\": {\n",
    "    \"output\": {\n",
    "      \"maxScore\": {\n",
    "        \"$max\": \"$score\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "},\n",
    "{\n",
    "  \"$addFields\": {\n",
    "    \"normalizedScore\": {\n",
    "      \"$divide\": [\n",
    "        \"$score\", \"$maxScore\"\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "    ]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_pipeline = search_pipeline(query,search_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = collection.aggregate(search_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_scores = {doc['_id']: round(doc['normalizedScore'],2) for doc in search_result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution-Based Score Fusion (DBSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(scores):\n",
    "    min_score = min(scores.values())\n",
    "    max_score = max(scores.values())\n",
    "    return {doc_id: (score - min_score) / (max_score - min_score) for doc_id, score in scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_vector = normalize(vector_scores)\n",
    "normalized_keyword = normalize(keyword_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine scores\n",
    "fused_scores = {doc_id: (normalized_vector.get(doc_id, 0) + normalized_keyword.get(doc_id, 0)) \n",
    "                for doc_id in set(normalized_vector.keys()).union(normalized_keyword.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(fused_scores):\n",
    "    documents = []\n",
    "    # Retrieve documents by _id and add the fused score\n",
    "    for doc_id, score in fused_scores.items():\n",
    "        document = collection.find_one({'_id': doc_id})\n",
    "        if document:\n",
    "            document['fused_score'] = score\n",
    "            documents.append(document)\n",
    "    \n",
    "    # Sort documents by fused score in descending order\n",
    "    documents.sort(key=lambda x: x['fused_score'], reverse=True)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_documents = retrieve_documents(fused_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in sorted_documents:\n",
    "    doc_id = doc['_id']\n",
    "\n",
    "    # Assign vector score if it exists in the dictionary, else default to some value (e.g., 0)\n",
    "    doc['vector_score'] = vector_scores.get(doc_id, 0)\n",
    "\n",
    "    # Assign keyword score if it exists in the dictionary, else default to 0\n",
    "    doc['keyword_score'] = keyword_scores.get(doc_id, 0)\n",
    "\n",
    "    # Assign normalized vector score if it exists in the dictionary, else default to some value (e.g., 0)\n",
    "    doc['normalized_vector_score'] = normalized_vector.get(doc_id, 0)\n",
    "\n",
    "    # Assign normalized keyword score if it exists in the dictionary, else default to 0\n",
    "    doc['normalized_keyword_score'] = normalized_keyword.get(doc_id, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the sorted documents and their scores\n",
    "for doc in sorted_documents:\n",
    "    print(f\"Document ID: {doc['_id']}\\n paragraph: {doc['sentence']}\\n  DBSF_Score: {round(doc['fused_score'],2)}\\n vector_Score: {round(doc['vector_score'],2)}\\n normalized_vector_score: {round(doc['normalized_vector_score'],2)}\\n keyword_score: {doc['keyword_score']}\\n normalized_keyword_score: {round(doc['normalized_keyword_score'],2)}\\n\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
