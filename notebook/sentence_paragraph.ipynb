{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MONGO_URI = \"mongodb+srv://deemish2:Hi0YG5ZfHu4AjaXy@contact-center-cluster.ywp7wi1.mongodb.net/?retryWrites=true&w=majority&appName=contact-center-cluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to your Atlas cluster\n",
    "mongodb_client = pymongo.MongoClient(MONGO_URI)\n",
    "\n",
    "# Define collection and index name\n",
    "db_name = \"contact-center\"\n",
    "collection_name = \"paragraph\"\n",
    "atlas_collection = mongodb_client[db_name][collection_name]\n",
    "vector_search_index = \"search_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/deemish2/cisco/mongodb-vector-search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paragraph = \"Sentence segmentation is the process of deciding where the sentences start or end in NLP. It is also known as sentence breaking or sentence boundary detection and is implemented in Python in the following way. Initially we need to import Spacy.\"\n",
    "# queries = [\"what is sentence segmentation?\", \"what is sentence breaking?\"]\n",
    "# terms = [\"sentence segmentation\", \"sentence boundary detection\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deemish2/mongo-atlas/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"sentence-transformers/nli-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_queries = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_terms = SentenceTransformer(\"paraphrase-MiniLM-L3-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"paragraph\": \"Sentence segmentation is the process of deciding where the sentences start or end in NLP. It is also known as sentence breaking or sentence boundary detection and is implemented in Python in the following way. Initially we need to import Spacy.\",\n",
    "        \"queries\": [\n",
    "            {\n",
    "                \"query\": \"what is sentence segmentation?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence segmentation\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"query\": \"what is sentence breaking?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence boundary detection\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"index\": 0\n",
    "    },\n",
    "    {\n",
    "        \"paragraph\": \"In natural language processing, sentence segmentation is the process of identifying the boundaries between sentences in a text. This is important for various NLP tasks, such as part-of-speech tagging, named entity recognition, and parsing.\",\n",
    "        \"queries\": [\n",
    "            {\n",
    "                \"query\": \"why is sentence segmentation important?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence segmentation\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"query\": \"how to perform sentence segmentation?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence segmentation\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"index\": 1\n",
    "    },\n",
    "    {\n",
    "        \"paragraph\": \"Sentence breaking is the process of identifying the boundaries between sentences in a text. This is typically done by detecting punctuation marks such as periods, question marks, and exclamation points.\",\n",
    "        \"queries\": [\n",
    "            {\n",
    "                \"query\": \"what is the purpose of sentence breaking?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence boundary detection\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"query\": \"how to break sentences in a text?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence boundary detection\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"index\": 2\n",
    "    },\n",
    "    {\n",
    "        \"paragraph\": \"Sentence boundary detection can be challenging in some cases, such as when sentences are not clearly separated by punctuation. In such cases, machine learning techniques can be used to identify sentence boundaries based on patterns in the text.\",\n",
    "        \"queries\": [\n",
    "            {\n",
    "                \"query\": \"how to detect sentence boundaries?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence boundary detection\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"query\": \"what are the challenges of sentence boundary detection?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence boundary detection\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"index\": 3\n",
    "    },\n",
    "    {\n",
    "        \"paragraph\": \"Spacy is a popular Python library for natural language processing. It provides pre-trained models and tools for various NLP tasks, including sentence segmentation, part-of-speech tagging, named entity recognition, and dependency parsing.\",\n",
    "        \"queries\": [\n",
    "            {\n",
    "                \"query\": \"how to use Spacy for sentence segmentation?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence segmentation\",\n",
    "                    \"Spacy\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"query\": \"what are the features of Spacy?\",\n",
    "                \"terms\": [\n",
    "                    \"Spacy\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"index\": 4\n",
    "    },\n",
    "    {\n",
    "        \"paragraph\": \"To perform sentence segmentation in Spacy, you can use the sentencizer component, which is part of the default processing pipeline. This component is responsible for identifying sentence boundaries based on punctuation and other features.\",\n",
    "        \"queries\": [\n",
    "            {\n",
    "                \"query\": \"how does Spacy perform sentence segmentation?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence segmentation\",\n",
    "                    \"Spacy\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"query\": \"what is the sentencizer component in Spacy?\",\n",
    "                \"terms\": [\n",
    "                    \"Spacy\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"index\": 5\n",
    "    },\n",
    "    {\n",
    "        \"paragraph\": \"Sentence segmentation can also be done using rule-based approaches, where specific rules are defined to identify sentence boundaries based on patterns in the text. However, rule-based approaches may not be as accurate as machine learning-based approaches.\",\n",
    "        \"queries\": [\n",
    "            {\n",
    "                \"query\": \"what are rule-based approaches to sentence segmentation?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence segmentation\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"query\": \"why may rule-based approaches be less accurate for sentence segmentation?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence segmentation\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"index\": 6\n",
    "    },\n",
    "    {\n",
    "        \"paragraph\": \"In summary, sentence segmentation is a fundamental task in natural language processing that involves identifying the boundaries between sentences in a text. It is important for various NLP tasks and can be performed using different approaches, including machine learning and rule-based methods.\",\n",
    "        \"queries\": [\n",
    "            {\n",
    "                \"query\": \"what is the summary of sentence segmentation?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence segmentation\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"query\": \"why is sentence segmentation important in NLP?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence segmentation\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"index\": 7\n",
    "    },\n",
    "    {\n",
    "        \"paragraph\": \"In conclusion, sentence boundary detection is an important task in natural language processing that involves identifying the boundaries between sentences in a text. It is necessary for various NLP tasks, such as parsing, machine translation, and information retrieval.\",\n",
    "        \"queries\": [\n",
    "            {\n",
    "                \"query\": \"what is the conclusion of sentence boundary detection?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence boundary detection\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"query\": \"why is sentence boundary detection important in NLP?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence boundary detection\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"index\": 8\n",
    "    },\n",
    "    {\n",
    "        \"paragraph\": \"To conclude, sentence breaking is the process of identifying the boundaries between sentences in a text. It is essential for various NLP tasks, such as text summarization, sentiment analysis, and document classification.\",\n",
    "        \"queries\": [\n",
    "            {\n",
    "                \"query\": \"what is the importance of sentence breaking?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence boundary detection\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"query\": \"how does sentence breaking help in NLP?\",\n",
    "                \"terms\": [\n",
    "                    \"sentence boundary detection\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"index\": 9\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for record in data:\n",
    "    paragraph = record[\"paragraph\"]\n",
    "    index = record[\"index\"]\n",
    "    # queries = [query[\"query\"] for query in record[\"queries\"]]\n",
    "    # terms = [term for query in record[\"queries\"] for term in query[\"terms\"]]  # Flatten terms list\n",
    "    \n",
    "    paragraph_embedding = model.encode([paragraph])[0]\n",
    "    # query_embeddings = model.encode(queries)\n",
    "    # term_embeddings = model_terms.encode(terms)\n",
    "    # query_embedding_list = [embedding.tolist() for embedding in query_embeddings]\n",
    "\n",
    "    processed_record = {\n",
    "        \"paragraph\": {\"index\":index,\"sentence\": paragraph, \"sen_embedding\": paragraph_embedding.tolist()}\n",
    "                    \n",
    "\n",
    "        # \"terms\": [{\"term\": term} for term in terms)]\n",
    "    }\n",
    "    atlas_collection.insert_one(processed_record)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in data:\n",
    "    queries = [query[\"query\"] for query in record[\"queries\"]]\n",
    "    query_embeddings = model.encode(queries)\n",
    "    query_embedding_list = [embedding.tolist() for embedding in query_embeddings]\n",
    "for record in atlas_collection.find():\n",
    "    atlas_collection.update_one(\n",
    "        {\"_id\": record[\"_id\"]},\n",
    "        {\n",
    "            \"$set\": {\n",
    "                \"paragraph.query1\": queries[0],\n",
    "                \"paragraph.query_embedding1\": query_embedding_list[0],\n",
    "                \"paragraph.query2\": queries[1],\n",
    "                \"paragraph.query_embedding2\": query_embedding_list[1]\n",
    "            }\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ,\"query_embedding1\": query_embedding_list[0], \"query_embedding2\": query_embedding_list[1]},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 10, 'electionId': ObjectId('7fffffff000000000000003b'), 'opTime': {'ts': Timestamp(1715867981, 13), 't': 59}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1715867981, 23), 'signature': {'hash': b'\\xe6\\x11\\xb6@\\x1d\\xc5\\x07\\xf7\\xba\\xd9\\xceM\\x81O\\x86\\x15\\xe1\\xb3\\n\\x94', 'keyId': 7311689974670163974}}, 'operationTime': Timestamp(1715867981, 13)}, acknowledged=True)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlas_collection.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(query):\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$search\": {\n",
    "                \"index\": \"search_index\",\n",
    "                \"text\": {\n",
    "                    \"query\": query,\n",
    "                    \"path\": {\n",
    "                        \"wildcard\": \"*\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"paragraph.sentence\": 1,\n",
    "                \"score\": { \"$meta\": \"searchScore\" }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is sentence segmentation?\"\n",
    "pipeline = create_pipeline(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mongodb_client[\"contact-center\"][\"paragraph\"].aggregate(pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymongo.command_cursor.CommandCursor object at 0x3461dfe80>\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in result:\n",
    "    print(\"Sentence:\", i[\"paragraph\"][\"sentence\"])\n",
    "    print(\"Score:\", i[\"score\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Sentence segmentation is the process of deciding where the sentences start or end in NLP. It is also known as sentence breaking or sentence boundary detection and is implemented in Python in the following way. Initially we need to import Spacy.\n",
      "Score: 0.4125702977180481\n",
      "\n",
      "Sentence: Sentence segmentation is the process of deciding where the sentences start or end in NLP. It is also known as sentence breaking or sentence boundary detection and is implemented in Python in the following way. Initially we need to import Spacy.\n",
      "Score: 0.4125702977180481\n",
      "\n",
      "Sentence: To perform sentence segmentation in Spacy, you can use the 'sentencizer' component, which is part of the default processing pipeline. This component is responsible for identifying sentence boundaries based on punctuation and other features.\n",
      "Score: 0.41165703535079956\n",
      "\n",
      "Sentence: To perform sentence segmentation in Spacy, you can use the 'sentencizer' component, which is part of the default processing pipeline. This component is responsible for identifying sentence boundaries based on punctuation and other features.\n",
      "Score: 0.41165703535079956\n",
      "\n",
      "Sentence: In natural language processing, sentence segmentation is the process of identifying the boundaries between sentences in a text. This is important for various NLP tasks, such as part-of-speech tagging, named entity recognition, and parsing.\n",
      "Score: 0.39946871995925903\n",
      "\n",
      "Sentence: In natural language processing, sentence segmentation is the process of identifying the boundaries between sentences in a text. This is important for various NLP tasks, such as part-of-speech tagging, named entity recognition, and parsing.\n",
      "Score: 0.39946871995925903\n",
      "\n",
      "Sentence: In summary, sentence segmentation is a fundamental task in natural language processing that involves identifying the boundaries between sentences in a text. It is important for various NLP tasks and can be performed using different approaches, including machine learning and rule-based methods.\n",
      "Score: 0.37703844904899597\n",
      "\n",
      "Sentence: In summary, sentence segmentation is a fundamental task in natural language processing that involves identifying the boundaries between sentences in a text. It is important for various NLP tasks and can be performed using different approaches, including machine learning and rule-based methods.\n",
      "Score: 0.37703844904899597\n",
      "\n",
      "Sentence: Spacy is a popular Python library for natural language processing. It provides pre-trained models and tools for various NLP tasks, including sentence segmentation, part-of-speech tagging, named entity recognition, and dependency parsing.\n",
      "Score: 0.36666175723075867\n",
      "\n",
      "Sentence: Spacy is a popular Python library for natural language processing. It provides pre-trained models and tools for various NLP tasks, including sentence segmentation, part-of-speech tagging, named entity recognition, and dependency parsing.\n",
      "Score: 0.36666175723075867\n",
      "\n",
      "Sentence: Sentence segmentation can also be done using rule-based approaches, where specific rules are defined to identify sentence boundaries based on patterns in the text. However, rule-based approaches may not be as accurate as machine learning-based approaches.\n",
      "Score: 0.24416422843933105\n",
      "\n",
      "Sentence: Sentence segmentation can also be done using rule-based approaches, where specific rules are defined to identify sentence boundaries based on patterns in the text. However, rule-based approaches may not be as accurate as machine learning-based approaches.\n",
      "Score: 0.24416422843933105\n",
      "\n",
      "Sentence: Sentence breaking is the process of identifying the boundaries between sentences in a text. This is typically done by detecting punctuation marks such as periods, question marks, and exclamation points.\n",
      "Score: 0.1704876720905304\n",
      "\n",
      "Sentence: Sentence breaking is the process of identifying the boundaries between sentences in a text. This is typically done by detecting punctuation marks such as periods, question marks, and exclamation points.\n",
      "Score: 0.1704876720905304\n",
      "\n",
      "Sentence: To conclude, sentence breaking is the process of identifying the boundaries between sentences in a text. It is essential for various NLP tasks, such as text summarization, sentiment analysis, and document classification.\n",
      "Score: 0.16767562925815582\n",
      "\n",
      "Sentence: To conclude, sentence breaking is the process of identifying the boundaries between sentences in a text. It is essential for various NLP tasks, such as text summarization, sentiment analysis, and document classification.\n",
      "Score: 0.16767562925815582\n",
      "\n",
      "Sentence: In conclusion, sentence boundary detection is an important task in natural language processing that involves identifying the boundaries between sentences in a text. It is necessary for various NLP tasks, such as parsing, machine translation, and information retrieval.\n",
      "Score: 0.15977640450000763\n",
      "\n",
      "Sentence: In conclusion, sentence boundary detection is an important task in natural language processing that involves identifying the boundaries between sentences in a text. It is necessary for various NLP tasks, such as parsing, machine translation, and information retrieval.\n",
      "Score: 0.15977640450000763\n",
      "\n",
      "Sentence: Sentence boundary detection can be challenging in some cases, such as when sentences are not clearly separated by punctuation. In such cases, machine learning techniques can be used to identify sentence boundaries based on patterns in the text.\n",
      "Score: 0.014888879843056202\n",
      "\n",
      "Sentence: Sentence boundary detection can be challenging in some cases, such as when sentences are not clearly separated by punctuation. In such cases, machine learning techniques can be used to identify sentence boundaries based on patterns in the text.\n",
      "Score: 0.014888879843056202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "for i in result:\n",
    "    print(\"Sentence:\", i[\"paragraph\"][\"sentence\"])\n",
    "    print(\"Score:\", i[\"score\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = db.paragraph.aggregate([\n",
    "  {\n",
    "    \"$vectorSearch\": {\n",
    "      \"what is sentence segmentation?\"\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"$project\": {\n",
    "      \"<field-to-include>\": 1,\n",
    "      \"<field-to-exclude>\": 0,\n",
    "      \"score\": { \"$meta\": \"vectorSearchScore\" }\n",
    "    }\n",
    "  }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\n",
    "        \"$vectorSearch\": {\n",
    "            \"index\": \"vector_index\",\n",
    "            \"path\": \"sen_embedding\",\n",
    "            \"queryVector\": list(np.random.uniform(-1, 1, 768)),\n",
    "            \"numCandidates\": 20,\n",
    "            \"limit\": 10\n",
    "        }\n",
    "    }, {\n",
    "        \"$project\": {\n",
    "            \"score\": {\n",
    "                \"$meta\": \"vectorSearchScore\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypbrid search\n",
    "\n",
    "query_text = \"sentence segmentation\"\n",
    "query_vector = model.encode([paragraph])[0]\n",
    "\n",
    "result = db.paragraph.aggregate([\n",
    "    {\n",
    "        \"$search\": {\n",
    "            \"compound\": {\n",
    "                \"must\": [\n",
    "                    {\n",
    "                        \"text\": {\n",
    "                            \"query\": query_text,\n",
    "                            \"path\": [\"paragraph.sentence\", \"queries.query\", \"terms.term\"]\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"vector\": {\n",
    "                            \"path\": \"paragraph.embedding1024\",\n",
    "                            \"query\": query_vector,\n",
    "                            \"maxDistance\": 0.5\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete_many({})  # Clear the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.paragraph.aggregate([\n",
    "  {\n",
    "    \"$vectorSearch\": {\n",
    "      \"index\": \"vector_index\",\n",
    "      \"path\": \"embedding1024\",\n",
    "      \"queryVector\": list(np.random.uniform(-1,1,1024)),\n",
    "      \"numCandidates\": 200,\n",
    "      \"limit\": 5\n",
    "    }\n",
    "  }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.explain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mongo-atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
